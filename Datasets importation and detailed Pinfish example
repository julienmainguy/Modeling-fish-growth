library(fishmethods)
library(FSA)
library(FSAdata)
library(hnp)
library(nlraa)
library(nlstools)
library(scam)
library(tidyverse)
library(visreg)

## The importation of all but one of the 21 publicly-available datasets presented in Table 1 of the main text
## can be directly achieved once the "fishmethods" and "FSAdata" packages have been activated in R. Note that
## additional steps to remove some sampled fish may be required, which is the case for the three detailed examples
## presented in the main text (1) pinfish, (2) male black drums, and (3) female haddocks. Given that these three
## datasets are presented in more details, here are the additional code that were applied:

## Example 1: pinfish (Nelson 2002)

## The original pinfish dataset, which is the only one linked to the "fishmethods" package (Nelson 2025), has 670 sampled  
## males and females, and using the headtail() function of the "FSA" package will show the first and last three lines of 
## this dataset to confirm this.

headtail(pinfish)


## As indicated in Nelson (2002) and the related Fig. 4B presented in this study, both sexes were combined and with the
## analyses only conducted for pinfish exhibiting a standard length (sl) of 66 mm and greater, up to the maximum of 255 mm.
## The pinfish dataset was thus first reduced by only keeping fish with this range of lengths.

pinfish <- pinfish[which(pinfish$sl > 65),]


## The descriptive statistics of this reduced dataset, as obtained with the Summarize() function of "FSA", now indicate that
## n = 665 pinfish exhibiting an sl varying between 66 and 255 mm are considered. Note that Nelson (2002) reports using n = 658
## pinfish in his analyses, such that apparently seven additional individual fish were considered here.

Summarize(sl ~ 1, data = pinfish)


## Example 2: male black drums (Ogle 2016)

## This example is originally used in the excellent fisheries-related textbook of Ogle (2016, Chapter 12) to show the detailed
## application of the von Bertalanffy growth model (VBGM) in which only the males from the BlackDrum2001 dataset found in "FSAdata"
## are used. As a first step, only the males are kept and, as done by Ogle (2016), a 51-year-old (oldest) male is also removed,
## leaving a total of 74 males aged between 3 and 42 years old. To be consistent with Ogle (2016), the reduced data is referred to
## as *bdm* for black drum males.

bdm <- BlackDrum2001 [which(BlackDrum2001$sex == "male"),]
bdm <- bdm[which(bdm$otoage < 51),]
Summarize(otoage ~ 1, data = bdm)


## Example 3: female haddocks (Honsey et al. 2017)

## This is the only dataset hosted on Dryad: https://datadryad.org/dataset/doi:10.5061/dryad.vb957 but to facilitate its importation
## into R, the same dataset has been made available here in a .txt format but in which *Season = SPRING*, *Year = 2015*, and *Sex = 2* 
## (i.e., female), correspond to an information that is common to all sampled female haddocks, such that it was removed. This modified
## dataset is found on this same repository and can be automatically imported into R from using the following url link together with 
## the read.delim() function.

url <- "https://raw.githubusercontent.com/julienmainguy/Modeling-fish-growth/refs/heads/main/haddock.txt"
haddock <- read.delim(url)


## This dataset was however further reduced by Honsey et al. (2017) by discarding the two smallest females despite the fact that these
## two observations did not appear to represent outliers, but could possibly have had a leverage effect on the linear relationship describing
## the first phase of the biphasic growth model and could thus possibly having been removed for such reason. Regardless of the reason 
## behind their removal, the original dataset was reduced to n = 359 by only containing female haddocks exhibiting a total lenght (tl) 
## of 20 cm or more.

haddock <- haddock[which(haddock$TotalLength >= 20),]
Summarize(Age ~ 1, data = haddock)


## In the other 18 examples, the removal of NA's sometimes needed to be performed prior to analyze the length-at-age data, such as in the
## RuffeSLRH92 data with n = 738 sampled fish of which only 12 had their age identified, as indicated from using the Summarize() function
## of "FSA" under *nvalid*, such that all the sampled fish with NA's for the *age* variable were removed.

Summarize(age ~ 1, data = RuffeSLRH92)

RuffeSLRH92 <- RuffeSLRH92[!is.na(RuffeSLRH92$age),]
Summarize(age ~ 1, data = RuffeSLRH92)


## NOTE

## As the overall analytical approach is identical for all datasets, only the analysis of the first example for the 665 pinfish (Nelson 2002)
## is shown below.


############################## COMMONLY-USED GROWTH MODELS (VON BERTALANFFY, GOMPERTZ, AND LOGISTIC) #########################################

## Application of the VBGM, with the Gompertz and logistic growth models following the same approach. First, the von Bertalanffy growth
## function, i.e. VB_fun(), is defined, as for the Gompertz and logistic ones (i.e., GGM and LGM, respectively), using "FSA".

VB_fun <- makeGrowthFun(type = "von Bertalanffy")
GZ_fun <- makeGrowthFun(type = "Gompertz")
LG_fun <- makeGrowthFun(type = "logistic")


## Starting values for the VBGM are first estimated and stored in the object *sv_pinfish_VB*, with the same step identically achieved for
## the GGM and LGM (not shown), again using "FSA".

sv_pinfish_VB <- findGrowthStarts(sl ~ age, 
                                  type = "von Bertalanffy",
                                  plot = TRUE,
                                  data = pinfish)


## Obtain the final VBGM from jointly using the VB_fun() function and estimated starting values (i.e., *sv_pinfish_VB*)

m_pinfish_VB <- nls(sl ~ VB_fun(age, Linf, K, t0),
                    start = sv_pinfish_VB, 
                    data = pinfish)


## Yield the summary output and ask for the estimation of the correlation coefficients between the three growth parameters, as provided by the
## "nlstools" package. Note the extremely high values of the correlation coefficients, especially betweeen Linf and K, and also K and t0. Such
## strong correlations between parameters are not uncommon.

summary(m_pinfish_VB, correlation = TRUE)


## MODEL ADEQUACY

## Check the adequacy of *m_pinfish_VB* with newly-available helper functions for the "hnp" package. A general Growth Function (GF) must first be created
## and is identically used for the VBGM, GGM, and LGM. But first, the (i) model, (ii) specific growth function, and (iii) dataset are defined for their use 
## with the associated code. Note that all the code rely on the information provided for model, growth_fun, and dataset. If the variable *age* is spelled
## otherwise, such as *Age*, it has to be changed too in the code (see lines 148, 160, and 167 below), given that R scripts are case-sensitive.

model <- m_pinfish_VB
growth_fun <- VB_fun
dataset <- pinfish

GF <- function(formula, start, data) {
               y <- data[[paste(formula[[2]])]]
                        fit <- nls(formula = formula,
                                   start = start,
                                   data = data)
            res <- y - as.numeric(fitted(fit))
      return(list(fit = fit, residuals = res))
}


## The growth model being assessed for its adequacy, here *m_pinfish_VB*, is then refitted as the *original_model* with the just-created
## GF() function and the specific one for the investigated growth model, here VB_fun(), which has already been defined. 

original_model <- GF(sl ~ VB_fun(age, Linf, K, t0), 
                     start = sv_pinfish_VB,
                     data = dataset)


## Then, the helper functions dfun(), sfun(), and ffun() are defined to be used with the hnp() function of "hnp". The dfun() and sfun()
## functions remain the same at all times, whereas the ffun() function must list the three specific growth parameters being used (line 167). 

dfun <- function(obj) obj$residuals

sfun <- function(n, obj) {
  theta <- coef(obj$fit)
  mu <- growth_fun(dataset$age, theta[1], theta[2], theta[3])
  sigma <- sigma(obj$fit)
  y <- rnorm(length(mu), mu, sigma)
  return(y)
}

ffun <- function(newresp) {
  fit <- GF(newresp ~ growth_fun(age, Linf, K, t0), 
            start = sv_pinfish_VB,
            data = dataset %>% mutate(newresp = newresp))
  return(fit)
}


## Adequacy assessment based on a single diagnostic iteration with "hnp". A half-normal plot with a simulated envelope is produced.
## Because of the simulations being used, each requested iteration will produce results that slightly vary. The paint = TRUE argument
## is used such that the residuals found outside the envelope are shown in red, whereas the print = TRUE argument displays the number 
## and percentage of residuals found outside the envelope directly on the half-normal plot. Note that performing another "hnp" iteration 
## will often produce a slightly different percentage value each time as a result of the model-based simulations being performed.

hnp(original_model,
    newclass = TRUE,
    diagfun = dfun,
    simfun = sfun,
    fitfun = ffun,
    how.many.out = TRUE,
    paint = TRUE,
    print = TRUE)


## Adequacy assessment based on n = 10 diagnostic iterations with "hnp". The seed *2026* is solely used for reproducibility.
## The results of all the requested diagnostic iterations are then saved in the *hnp_summary* object.

set.seed(2026)
n <- 10
hnp_obj <- list()
for(i in 1:n) {
  hnp_obj[[i]] <- hnp(original_model,
                   newclass = TRUE,
                   diagfun = dfun,
                   simfun = sfun,
                   fitfun = ffun,
                   how.many.out = TRUE,
                   plot.sim = FALSE)
}

hnp_summary <- sapply(hnp_obj, function(x) x$out / x$total * 100) 


## Estimate the modal percentage of residuals found outside the simulated envelope using the *hnp_summary* object.

return_max <- function(numvec) {
  dens <- density(numvec)
  return(dens$x[which.max(dens$y)][1])
}
round(return_max(hnp_summary), 2)


## MODEL IN-SAMPLE PREDICTIVE PERFORMANCE

## Estimate the (unadjusted) coefficient of determination (R2) with the R2M() function of the "nlraa" package.

R2M(m_pinfish_VB)$R2 * 100


## ADJUSTED ROOT MEAN SQUARE ERROR (RMSE_adj)

n <- length(pinfish$age)
logLik <- logLik(m_pinfish_VB)
P <- attributes(logLik)$df
prediction <- predict(m_pinfish_VB, pinfish, type = "response")
RSS <- sum((prediction - pinfish$sl)^2)
(RMSE_adj <- sqrt(RSS / (n - P)))


## LEAVE-ONE-OUT CROSS-VALIDATION (LOO-CV) WITH ONE-STANDARD-ERROR (1SE) RULE BASED ON THE MEAN RMSE

## Note that because this dataset is quite large (n = 665), this process takes about one minute to be completed.
## In this example, removing one observation at a time did not create modeling issues, but this can occur and
## would result in having one or likely more zeros values in the data frame containing all the computed RMSE values.
## If such situation occurs, the Summarize() function of FSA will generate an additional metric *percZero* to
## indicate the percentage of zeros in the considered dataset. As no observed value is expected to directly correspond
## to the predicted value, a zero is highly likely to be attributable to a convergence issue or else. As a result,
## the LOO-CV process will be unreliable as the mean RMSE will be further reduced (i.e., lower mean RMSE = better) by
## the presence of these zeros. Removing these zeros will not allow to compare the mean RMSE on a same basis neither 
## when it is compared to another candidate model that experienced no analytical issues.

n <- length(pinfish$age)                                                                             # as already defined in the previous step above
RMSE <- numeric(n)

for (i in 1:n) {
  train <- pinfish[-i, ]                                                                             # leave out the i-th observation to create a new *train* dataset each time
  test <- pinfish[i, ]                                                                               # keep the i-th observation as the *test* dataset (n = 1) each time 
  sv_pinfish_VB <- findGrowthStarts(sl ~ age, type = "von Bertalanffy", plot = TRUE, data = train)   # estimate the starting values based on the *train* dataset
  model <- nls(sl ~ VB_fun(age, Linf, K, t0), start = sv_pinfish_VB, data = train)                   # estimate the three growth parameters for the final VBGM based on the "train" dataset
  prediction <- predict(model, newdata = test, type = "response")                                    # yield the related predicted value for the single observation contained in the "test" dataset
  RMSE[i] <- sqrt(mean((prediction-test$sl)^2))                                                      # calculate the RMSE each time
}

results_pinfish_VB <- data.frame(METHOD = "VB", RMSE)                                                # store all the RMSE values in a same data frame

Summarize(RMSE ~ 1, data = results_pinfish_VB)                                                       # obtain the descriptive statistics, including the mean RMSE from this LOO-CV approach

(sd(results_pinfish_VB$RMSE)/sqrt(n))                                                                # valculate the estimated standard error (SE) to be used for the 1SE rule

logLik <- logLik(m_pinfish_VB)              
(attributes(logLik)$df)                                                                              # obtain the parameter degrees of freedom (d.f.) or P, which is d.f. = 4 for the VBGM, GGM, and LGM


## BAYESIAN INFORMATION CRITERION (BIC)

## BIC(m_pinfish_VB, m_pinfish_GZ, m_pinfish_LG)                                                     # once the GGM and LGM have also been fitted


## PREDICTED VALUES

nd <- data.frame(age = seq(min(pinfish$age), max(pinfish$age), by = 0.02))                           # select an incremental value (i.e., by = 0.02) allowing to offer a smoothed curve
estimate <- predict(m_pinfish_VB, nd, type = "response")
results <- data.frame(nd, estimate)

plot(sl ~ age, data = pinfish)                                                                       # simple plot showing the observed values
points(estimate ~ age, data = results, pch = 20, type = "b", lwd = 1.5, col = "red")                 # adding the predicted values to assess their fit to the length-at-age data


############################## SHAPE-CONSTRAINED ADDITIVE MODELING (SCAM) FRAMEWORK ###########################################

## The smooth function s() applied to *age* below imposes through *bs = "micv"* a monotically (m) increasing (i) and convave (cv) 
## curvilinear pattern using the "scam" package.

## Gaussian distribution with identity link

m_pinfish_SCAM_GAUSSIAN <- scam(sl ~ s(age, bs = "micv"),    
                                family = gaussian,
                                optimizer = "efs",
                                data = pinfish)

summary(m_pinfish_SCAM_GAUSSIAN)


## Use the gamma distribution with log link as an alternative

m_pinfish_SCAM_GAMMA <- scam(sl ~ s(age, bs = "micv"),
                             family = Gamma(link = "log"),
                             optimizer = "efs",
                             data = pinfish)

summary(m_pinfish_SCAM_GAMMA)


## MODEL ADEQUACY

## Check the adequacy of both models from using slightly modified helper functions for "hnp" presented in Mainguy et al. (2026) for GAMs fitted with "mgcv".
## Given that the "scam" package is a direct extension of "mgcv", the required helper functions are nearly-identical. In all cases, the sfun() helper function
## must be correctly specified relative to the distribution family used, i.e. Gaussian or gamma with log link in this study (see Mainguy et al. 2026). Here,
## only the modal percentage of residuals found outside the simulated envelope is presented, but producing a single half-normal plot can similarly be done as for
## the VBGM presented above. First, the (i) model, (ii) distribution family, (iii) optimizer, and (iv) dataset used are specified to then process with the step of 
## adequacy assessment. The ffun() helper function always need to have the right-part next to *resp ~* identical to the model being tested (e.g., if *age* is written
## as *Age* for instance). 

## Assessment of the Gaussian SCAM requiring that the normality and homoscedasticity assumptions are sufficiently respected. Takes longer than for the VBGM.

model <- m_pinfish_SCAM_GAUSSIAN 
family <- gaussian
optimizer <- "efs"
dataset <- pinfish

dfun <- function(obj) resid(obj, type = "deviance")

sfun <- function(n, obj) {
            y <- rnorm(nrow(dataset),
                       mean = predict(model, type = "response"),
                       sd = sqrt(model$sig2))
            return(y)
}

ffun <- function(resp) {
             scam(resp ~ s(age, bs = "micv"),                            # the *age* variable must be correcly typed
                  family = family,
                  optimizer = optimizer,
                  data = dataset)
}

set.seed(2025)
n <- 10
hnp_obj <- list()
for (i in 1:n) {
  hnp_obj[[i]] <- hnp(model, 
                      newclass = TRUE,
                      diagfun = dfun,
                      simfun = sfun,
                      fitfun = ffun,
                      how.many.out = TRUE,
                      plot.sim = FALSE)
}

hnp_summary <- sapply(hnp_obj, function(x) x$out / x$total * 100) 

return_max <- function(numvec) {
  dens <- density(numvec)
  return(dens$x[which.max(dens$y)][1])
}
round(return_max(hnp_summary), 2)


## Assessment of the gamma SCAM requiring that the variance is sufficiently proportional to the mean. Given that the observed data do not apparently 
## behave in such a way since the variation in lengths is not really increasing as fish age, this will likely be detected by "hnp" and thus provide
## a modal percentage of residuals found outside the envelope higher than the proposed 10%-threshold for an acceptable fit. This assessment takes a bit
## more time than that of the Gaussian SCAM just performed above.

model <- m_pinfish_SCAM_GAMMA
family <- Gamma(link = "log")
optimizer <- "efs"
data <- dataset

dfun <- function(obj) resid(obj, type = "deviance")

sfun <- function(n, obj) {
  mu_hat <- fitted(obj)
  phi <- summary(obj)$dispersion
  shape <- 1 / phi
  scale <- mu_hat * phi
  y <- rgamma(n = length(mu_hat), shape = shape, scale = scale)
  return(y)
}

ffun <- function(resp) {
        scam(resp ~ s(age, bs = "micv"),                            # the *age* variable must be correcly typed
             family = family,
             optimizer = optimizer,
             data = dataset)
}

set.seed(2025)
n <- 10
hnp_obj <- list()
for(i in 1:n) {
  hnp_obj[[i]] <- hnp(model,
                   newclass = TRUE,
                   diagfun = dfun,
                   simfun = sfun,
                   fitfun = ffun,
                   how.many.out = TRUE,
                   plot.sim = FALSE)
}

hnp_summary <- sapply(hnp_obj, function(x) x$out / x$total * 100) 

return_max <- function(numvec) {
  dens <- density(numvec)
  return(dens$x[which.max(dens$y)][1])
}
round(return_max(hnp_summary), 2)


## MODEL IN-SAMPLE PREDICTIVE PERFORMANCE

## The (unadjusted) coefficient of determination (R2) for a Gaussian SCAM or the (unadjusted) deviance explained (D2) for a gamma SCAM
## are directly provided in the scam() function output under "Deviance explained" (see main text). Briefly, D2 is the R2 analogue for
## non-Gaussian models, such as for the gamma SCAM, and is estimated as follows:

model <- m_pinfish_SCAM_GAMMA
(D2 <- 100 * (1 - model$deviance / model$null.deviance))          # should match the value provided under "Deviance explained" in the model output


## Note that the adjusted R2 provided in the scam() function output (i.e.,*R-sq.(adj)*) is only valid for the Gaussiance case (see the summary
## for the gamma SCAM as a proof of that where the estimated R2 actually has a lower value than R2_adj). If one needs to penalize D2 for model 
## complexity to yield an adjusted D2 (D2_adj), the proposed adjustement by Guisan and Zimmermann (2000) should be used, as presented in Mainguy 
## et al. (2026) for GAMs, and which first requires the calculation of D2 as just shown above (yielding D2_adj < D2, as it should):

model <- m_pinfish_SCAM_GAMMA
D2 <- 100 * (1 - model$deviance / model$null.deviance)
logLik <- logLik(model)
P <- attributes(logLik)$df
n <- summary(model)$n
(D2_adj <- 100 - ((n - 1) / (n - P) * (100 - D2)))


## RMSE_adj, LOO-CV with 1SE rule, and BIC

## The three different approaches used to compare the penalized goodness-of-fit of the up to five candidate growth models
## are completely identical to those described above for the VBGM. Below, only the Gaussian SCAM is considered to yield
## these values.

## IMPORTANT: 

## As opposed to the VBGM, GGM, and LGM, each SCAM will vary in its model parameter d.f. (P) depending on how many
## effective degrees of freedom (edf) it requires to generate the smoothed growth curve (i.e., less nonlinearity, less edf).
## The penalization of the model relies on the "equivalent-df" of the model incorporating both the df (i.e., intercept) and edf.
## As such, P for the RMSE_adj and the last part of the code for the LOO-CV and 1SE rule will provide the value reflecting the
## complexity of the considered SCAM, which is often > 4 (i.e., the fixed value of the VBGM) but can also sometimes be < 4.

## RMSE_adj (Gaussian SCAM)

n <- length(pinfish$age)
logLik <- logLik(m_pinfish_SCAM_GAUSSIAN)
P <- attributes(logLik)$df
prediction <- predict(m_pinfish_SCAM_GAUSSIAN, pinfish, type = "response")
RSS <- sum((prediction - pinfish$sl)^2)
(RMSE_adj <- sqrt(RSS / (n - P)))


## LOO-CV and 1SE rule (Gaussian SCAM)

n <- length(pinfish$age)
RMSE <- numeric(n)

for (i in 1:n) {
  train <- pinfish[-i, ]
  test <- pinfish[i, ]
  model <- scam(
  sl ~ s(age, bs = "micv"), family = gaussian, optimizer = "efs", data = train)
  prediction <- predict(model, newdata = test, type = "response")
  RMSE[i] <- sqrt(mean((prediction-test$sl)^2))
}

results_pinfish_SCAM_GAUSSIAN <- data.frame(METHOD = "SCAM_GAUSSIAN", RMSE)
Summarize(RMSE ~ 1, data = results_pinfish_SCAM_GAUSSIAN)

(sd(results_pinfish_SCAM_GAUSSIAN$RMSE)/sqrt(n))

logLik<-logLik(m_pinfish_SCAM_GAUSSIAN)
(attributes(logLik)$df)


## BIC

## Note that the inadequate gamma SCAM is much better supported than the adequate Gaussian SCAM when relying on BIC.
## Any information criteria, like AIC and BIC, will rank model regardless of whether they respect their distributional
## assumptions or not. In this case, the gamma SCAM was previously identified as being inadequate and therefore, should
## not be considered for model selection purposes, but is compared here to the Gaussian SCAM to illustrate this point.

BIC(m_pinfish_SCAM_GAUSSIAN, m_pinfish_SCAM_GAMMA)


## PREDICTED VALUES

## The predicted values of both models can be yielded in the exact same manner as presented for the VBGM above. However,
## this can be more rapidely achieved from making use of the visreg() function of the "visreg" package and asking to
## generate the predicted values and related uncertainty at the response scale. Below the code for the Gaussian SCAM to 
## which we also add the observed values with the points() function.

visreg(m_pinfish_SCAM_GAUSSIAN, scale = "response", rug = FALSE, ylim = c(min(pinfish$sl), max(pinfish$sl)))
points(sl ~ age, pch = 20, data = pinfish)
